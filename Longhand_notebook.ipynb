{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6cf54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Longhand - M. Cook - 2022\n",
    "##Takes text corpus and returns immersive visualization\n",
    "##https://github.com/Cook4986/Longhand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dcb409",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes Bag-of-Words and returns json dump of common nouns, Sketchfab models/uids, and relative percentage of occurance\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import json\n",
    "import requests\n",
    "from requests.exceptions import RequestException\n",
    "import time\n",
    "\n",
    "#select language models here: https://spacy.io/models\n",
    "#nlp = spacy.load(\"it_core_news_lg\")\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "#nlp = spacy.load(\"en_core_web_md\")\n",
    "nlp.max_length = 10000000\n",
    "stopwords = nlp.Defaults.stop_words\n",
    "\n",
    "#I/O\n",
    "BoW = \"...txt\"\n",
    "output = \".../Longhand/objects.txt\"\n",
    "\n",
    "#declarations\n",
    "model_size = 100000 #face count\n",
    "SKETCHFAB_API_URL = \"https://api.sketchfab.com/v3/search?type=models&count=1&max_face_count=\" + str(model_size) #note count parameter\n",
    "API_TOKEN = '...' #keep private\n",
    "results = 20 #target number of models, potentially limited by NER outputs\n",
    "start = time.time()\n",
    "\n",
    "#data structures\n",
    "nouns = [] #nouns in Bag-of-Words\n",
    "entities = [] #named entities\n",
    "freqs = [] # noun appearance frequencies\n",
    "objects = {} # key = common nouns; value(s) = [relative percentage of total objects, UID, model name, URL]\n",
    "\n",
    "#parse Bag-of-Words parts-of-speech with SpaCy\n",
    "with open(BoW, encoding=\"utf-8\") as file:\n",
    "    print(\"Tokenizing text...\")\n",
    "    iliad = file.read()\n",
    "document = nlp(iliad)\n",
    "document.text\n",
    "\n",
    "#collate nouns in corpus\n",
    "for token in document:\n",
    "    token = token.lemma_\n",
    "    if (token not in stopwords) & (token.pos_ == 'NOUN'): \n",
    "            nouns.append(token.text)\n",
    "\n",
    "#collate named entities, limited to categories with presumed sketchfab correspondences\n",
    "labelsEN = [\"PRODUCT\"] #[\"PRODUCT\"\"EVENT\",\"FAC\",\"WORK_OF_ART\",\"LOC\",\"NORP\",\"GPE\",\"ORG\"] #english model, add \"PERSON\"\n",
    "labelsIT = [\"LOC\"]# \"MISC\", \"ORG\",\"PER\"] #italian model, add \"PER\"\n",
    "for entity in document.ents:\n",
    "    for label in labelsIT:\n",
    "        if (token not in stopwords) & (entity.label_ == label):\n",
    "            entities.append(entity.text)\n",
    "\n",
    "#frequency & dictionary creation with common words\n",
    "word_freq = Counter(nouns) #nouns or entities\n",
    "common = word_freq.most_common(results)\n",
    "for word in common:\n",
    "    freqs.append(word[1])\n",
    "Sum = sum(freqs)\n",
    "for word in common:\n",
    "    flowt = (word[1] / Sum) * 100\n",
    "    percentage = round(flowt, 2)\n",
    "    objects[word[0]] = [percentage]\n",
    "print(\"nlp step complete\")\n",
    "print(\"\\n\")\n",
    "print(\"dictionary created\")\n",
    "print(\"\\n\")\n",
    "\n",
    "#Sketchfab API payload function \n",
    "##From https://sketchfab.com/developers/data-api/v3/python#example-python-model\n",
    "def _get_request_payload(*, data=None, files=None, json_payload=False):\n",
    "    \"\"\"Helper method that returns the authentication token and proper content type depending on\n",
    "    whether or not we use JSON payload.\"\"\"\n",
    "    data = data or {}\n",
    "    files = files or {}\n",
    "    headers = {'Authorization': 'Token {}'.format(API_TOKEN)}\n",
    "    if json_payload:\n",
    "        headers.update({'Content-Type': 'application/json'})\n",
    "        data = json.dumps(data)\n",
    "    return {'data': data, 'files': files, 'headers': headers}\n",
    "\n",
    "#query sketchfabs with nouns in BoW and return/write list of uids + model names\n",
    "for key in objects.keys():\n",
    "    key = str(key)\n",
    "    print(\"Searching: \" + key)\n",
    "    print(\"\\n\")\n",
    "    query = (\"&q=\"+(key)+\"&downloadable=true\")\n",
    "    search_endpoint = f'{SKETCHFAB_API_URL + query}'\n",
    "    payload = _get_request_payload() \n",
    "    response = requests.get(search_endpoint, **payload)\n",
    "    data = response.json()\n",
    "    print(\"\\n\")\n",
    "    for item in range(len(data['results'])):\n",
    "        url = (data['results'][item]['uri'])\n",
    "        uid = (data['results'][item]['uid'])\n",
    "        name = (str((data['results'][item]['name'])))\n",
    "        size = int(data['results'][item]['faceCount'])\n",
    "        if key.lower() in name.lower():\n",
    "            objects[key] += [name, uid, url]\n",
    "            print(\"the following model has been located: \")\n",
    "            print(str((data['results'][item]['name']))+(\" \\nuid: \")+(data['results'][item]['uid']))\n",
    "            if size > 50000:\n",
    "                print(\"\\n\")\n",
    "                print(\"Warning: Model size exceeds 50000 faces.\")\n",
    "            print(\"\\n\")\n",
    "            \n",
    "#write dictionary to disk \n",
    "with open(output, 'w') as file:\n",
    "    file.write(json.dumps(objects)) \n",
    "file.close()\n",
    "print(str(results) + \" most common objects in corpus written to disk\")\n",
    "\n",
    "#print number of suitable matches\n",
    "hits = []\n",
    "for key,value in objects.items():\n",
    "    if len(value) > 2:\n",
    "        hits.append(key)\n",
    "print((str(len(hits))) + \" suitable models located on Sketchfab\")\n",
    "print(\"\\n\")\n",
    "\n",
    "#terminate program\n",
    "end = time.time()\n",
    "print(str(end - start) + \" seconds elapsed\" )\n",
    "print(\"\\n\")\n",
    "print(\"have a nice day\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81b9b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Launches Blender from terminal and initiates model download script\n",
    "!/Applications/Blender.app/Contents/MacOS/Blender --python .../Longhand/Longhand_downloader.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42828964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notes\n",
    "##Tested on 9.2 MB text file (cookbooks) w/ en_core_web_lg model. Mac Desktop. Timed out.\n",
    "##Add \"working directory\", across scripts, to automate declarations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

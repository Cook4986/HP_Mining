{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6cf54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Longhand - M. Cook - 2022\n",
    "##Takes text corpus and returns immersive visualization\n",
    "##https://github.com/Cook4986/Longhand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6c36ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes Bag-of-Words and returns json dump of common nouns, Sketchfab models/uids, and relative percentage of occurance\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import json\n",
    "import requests\n",
    "from requests.exceptions import RequestException\n",
    "import time\n",
    "\n",
    "#select language model (https://spacy.io/models)\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "nlp.max_length = 100000000\n",
    "stopwords = nlp.Defaults.stop_words\n",
    "\n",
    "#I/O\n",
    "BoW = \"...txt\"#plaintext bag-of-words input\n",
    "output = \"...txt\" #See: \"Objects\" declaration, below, for structure\n",
    "\n",
    "#declarations\n",
    "model_size = 100000 #face count\n",
    "SKETCHFAB_API_URL = \"https://api.sketchfab.com/v3/search?type=models&count=24\"\n",
    "API_TOKEN = '...' #from Sketchfab - keep private\n",
    "results = 50 #target number of models, potentially limited by NER outputs\n",
    "slug = [\"cultural-heritage-history\"] #from: https://api.sketchfab.com/v3/categories\n",
    "start = time.time()\n",
    "\n",
    "#data structures\n",
    "nouns = [] #nouns in Bag-of-Words\n",
    "entities = [] #named entities\n",
    "freqs = [] # noun appearance frequencies\n",
    "objects = {} # key = common nouns; value(s) = [relative percentage of total objects, UID, model name, URL]\n",
    "\n",
    "#parse Bag-of-Words with SpaCy\n",
    "with open(BoW, encoding=\"utf-8\") as file:\n",
    "    print(\"Tokenizing text...\")\n",
    "    print(\"\\n\")\n",
    "    iliad = file.read()\n",
    "document = nlp(iliad)\n",
    "\n",
    "#collate nouns or named entities in corpus\n",
    "for token in document:\n",
    "    if (token not in stopwords) & (token.pos_ == 'NOUN'):\n",
    "            nouns.append(token.lemma_)\n",
    "        \n",
    "#select entity categories to search\n",
    "labels = [\"PRODUCT\",\"EVENT\",\"FAC\",\"WORK_OF_ART\",\"LOC\",\"ORG\"] \n",
    "#[\"PRODUCT\",\"EVENT\",\"FAC\",\"WORK_OF_ART\",\"LOC\",\"NORP\",\"GPE\",\"ORG\"] \n",
    "for entity in document.ents:\n",
    "    for label in labels:\n",
    "        if (entity not in stopwords) & (entity.label_ == label):\n",
    "            entities.append(entity.text)\n",
    "\n",
    "#collate common tokens (update for nouns or entities, below)       \n",
    "word_freq = Counter(entities) \n",
    "#word_freq = Counter(entities) \n",
    "common = word_freq.most_common(results)\n",
    "print(\"Common nouns in the target corpus include: \")\n",
    "print(\"\\n\")\n",
    "print(common)\n",
    "print(\"\\n\")\n",
    "\n",
    "#Sketchfab API payload function \n",
    "##From https://sketchfab.com/developers/data-api/v3/python#example-python-model\n",
    "def _get_request_payload(*, data=None, files=None, json_payload=False):\n",
    "    \"\"\"Helper method that returns the authentication token and proper content type depending on\n",
    "    whether or not we use JSON payload.\"\"\"\n",
    "    data = data or {}\n",
    "    files = files or {}\n",
    "    headers = {'Authorization': 'Token {}'.format(API_TOKEN)}\n",
    "    if json_payload:\n",
    "        headers.update({'Content-Type': 'application/json'})\n",
    "        data = json.dumps(data)\n",
    "    return {'data': data, 'files': files, 'headers': headers}\n",
    "\n",
    "#query sketchfabs with tokens and compile object dictionary with results\n",
    "for word in common:\n",
    "    key = str(word[0])\n",
    "    tag = key.lower()\n",
    "    #query = (\"&q=\"+(key)+\"&user=hmane\"+\"&downloadable=true&max_face_count=\" + str(model_size))\n",
    "    query = (\"&q=\" +(key)+\"&downloadable=true&max_face_count=\"+ str(model_size))\n",
    "    #query = (\"&q=\"+(key)+\"&downloadable=true\")\n",
    "    search_endpoint = f'{SKETCHFAB_API_URL + query}'\n",
    "    payload = _get_request_payload() \n",
    "    response = requests.get(search_endpoint, **payload)\n",
    "    data = response.json()\n",
    "    #print(data)\n",
    "    #parse json response\n",
    "    for item in range(len(data['results'])):\n",
    "        url = (data['results'][item]['uri'])\n",
    "        uid = (data['results'][item]['uid'])\n",
    "        name = (str((data['results'][item]['name'])))\n",
    "        if 'name' in (str((data['results'][item]['tags']))):\n",
    "            tags = (str((data['results'][item]['tags'][0]['name'])))\n",
    "        size = int(data['results'][item]['faceCount'])\n",
    "        #string matching keys against Sketchfab object names and tags\n",
    "        if (key.lower() in name.lower()) & (name not in objects) & (size != 0): #add try/except\n",
    "            freqs.append(word[1])\n",
    "            objects[word[0]] = [word[1]]\n",
    "            objects[key] += [name, uid, url, size] \n",
    "        elif (key.lower() in tags) & (name not in objects) & (size != 0):\n",
    "            freqs.append(word[1])\n",
    "            objects[word[0]] = [word[1]]\n",
    "            objects[key] += [name, uid, url, size]\n",
    "            print(\"tag used to pick model\")\n",
    "            print(\"\\n\")\n",
    "print(\"\\n\")      \n",
    "\n",
    "#write object (output) dictionary to disk \n",
    "with open(output, 'w') as file:\n",
    "    file.write(json.dumps(objects)) \n",
    "file.close()\n",
    "\n",
    "#print hits and relative percentages in corpus\n",
    "Sum = sum(freqs)\n",
    "for key,value in objects.items():\n",
    "    print(\"Model located for '\" + key + \"':\")\n",
    "    print(value[1].center(24))\n",
    "    flowt = (value[0] / Sum) * 100\n",
    "    percentage = round(flowt, 2)\n",
    "    print(\"Represents \" + str(percentage) + \"% of models identified.\")\n",
    "    if value[4] > 10000:\n",
    "                print(\"Warning: Model size exceeds 10000 faces \" + \"(\" + (str(value[4])) + \" faces)\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(str(len(objects)) + \" suitable models (of \"+ str(results) + \") located on Sketchfab written to disk\")\n",
    "print(\"\\n\")\n",
    "\n",
    "#terminate program\n",
    "end = time.time()\n",
    "print(str(end - start) + \" seconds elapsed\" )\n",
    "print(\"\\n\")\n",
    "print(\"have a nice day\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b93c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Launches Blender from terminal and initiates model download script\n",
    "!/Applications/Blender.app/Contents/MacOS/Blender --python .../Longhand_downloader.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ebeaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##To-Do##\n",
    "#notebook settings log\n",
    "#tags-based querying (line 89)\n",
    "#\"objects\" output global\n",
    "#collision detection\n",
    "#word2vec\n",
    "#Streamlit deployment\n",
    "#text-to-3D (AI)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

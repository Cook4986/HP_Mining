{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6cf54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Longhand - M. Cook - 2022\n",
    "##Takes text corpus and returns an immersive visualization\n",
    "##https://github.com/Cook4986/Longhand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dcb409",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes plain text document and outputs dictionary of common nouns or named entities [key]; relative percentage of occurance, Sketchfab models/uids/URLs [values] \n",
    "import spacy\n",
    "from collections import Counter\n",
    "import json\n",
    "import requests\n",
    "from requests.exceptions import RequestException\n",
    "import time\n",
    "\n",
    "#select language models here: https://spacy.io/models\n",
    "nlp = spacy.load(\"it_core_news_lg\")\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "#I/O\n",
    "BoW = \"...txt\"\n",
    "output = \".../objects.txt\"\n",
    "\n",
    "#declarations\n",
    "model_size = 100000 #face count\n",
    "SKETCHFAB_API_URL = \"https://api.sketchfab.com/v3/search?type=models&count=1&max_face_count=\" + str(model_size)\n",
    "API_TOKEN = '...'\n",
    "results = 100 #desired number of objects in visualization\n",
    "start = time.time()\n",
    "\n",
    "#data structures\n",
    "nouns = [] #all nouns in Bag-of-Words\n",
    "entities = [] #named entities\n",
    "freqs = [] # noun appearance frequencies\n",
    "objects = {} # key = common nouns; value(s) = [relative percentage of total objects, UID, model name, URL]\n",
    "    \n",
    "#parse Bag-of-Words parts-of-speech with SpaCy\n",
    "with open(BoW, encoding=\"utf-8\") as file:\n",
    "    iliad = file.read()\n",
    "document = nlp(iliad)\n",
    "document.text\n",
    "\n",
    "#collate nouns in corpus\n",
    "for token in document:\n",
    "    if token.pos_ == 'NOUN': \n",
    "        nouns.append(token.text)\n",
    "\n",
    "#collate named entities, limited to categories with presumed sketchfab correspondences\n",
    "labelsEN = [\"PRODUCT\",\"EVENT\",\"FAC\",\"WORK_OF_ART\",\"LOC\",\"NORP\",\"GPE\",\"ORG\"] #english model, add \"PERSON\"\n",
    "labelsIT = [\"LOC\", \"MISC\", \"ORG\",] #italian model, add \"PER\"\n",
    "for entity in document.ents:\n",
    "    for label in labelsIT:\n",
    "        if entity.label_ == label:\n",
    "            entities.append(entity.text)\n",
    "file.close()\n",
    "print(\"nlp step complete\")\n",
    "print(\"\\n\")\n",
    "\n",
    "#frequency & dictionary creation with common words\n",
    "word_freq = Counter(nouns) #nouns or entities\n",
    "common = word_freq.most_common(results)\n",
    "for word in common:\n",
    "    freqs.append(word[1])\n",
    "Sum = sum(freqs)\n",
    "for word in common:\n",
    "    flowt = (word[1] / Sum) * 100\n",
    "    percentage = round(flowt, 2)\n",
    "    objects[word[0]] = [percentage]\n",
    "print(\"object dictionary created\")\n",
    "print(\"\\n\")\n",
    "\n",
    "#Sketchfab API payload function \n",
    "##From https://sketchfab.com/developers/data-api/v3/python#example-python-model\n",
    "def _get_request_payload(*, data=None, files=None, json_payload=False):\n",
    "    \"\"\"Helper method that returns the authentication token and proper content type depending on\n",
    "    whether or not we use JSON payload.\"\"\"\n",
    "    data = data or {}\n",
    "    files = files or {}\n",
    "    headers = {'Authorization': 'Token {}'.format(API_TOKEN)}\n",
    "    if json_payload:\n",
    "        headers.update({'Content-Type': 'application/json'})\n",
    "        data = json.dumps(data)\n",
    "    return {'data': data, 'files': files, 'headers': headers}\n",
    "\n",
    "#query sketchfabs with nouns in BoW and return/write list of uids + model names\n",
    "for key in objects.keys():\n",
    "    print(\"Searching: \" + str(key))\n",
    "    print(\"\\n\")\n",
    "    query = (\"&q=\"+(str(key))+\"&downloadable=true\")\n",
    "    search_endpoint = f'{SKETCHFAB_API_URL + query}'\n",
    "    payload = _get_request_payload() \n",
    "    response = requests.get(search_endpoint, **payload)\n",
    "    data = response.json()\n",
    "    for item in range(len(data['results'])):\n",
    "        #if (str((data['results'][item]['name']))) != 0:\n",
    "        url = (data['results'][item]['uri'])\n",
    "        uid = (data['results'][item]['uid'])\n",
    "        name = (str((data['results'][item]['name'])))\n",
    "        objects[key] += [name, uid, url]\n",
    "        print(\"the following model been located: \")\n",
    "        print(str((data['results'][item]['name']))+(\" \\nuid: \")+(data['results'][item]['uid']))\n",
    "        print(\"\\n\")\n",
    "\n",
    "#write to disk and close program\n",
    "with open(output, 'w') as file:\n",
    "    file.write(json.dumps(objects)) \n",
    "file.close()\n",
    "print(str(results) + \" objects written to disk\")\n",
    "print(\"\\n\")\n",
    "end = time.time()\n",
    "print(str(end - start) + \" seconds elapsed\" )\n",
    "print(\"\\n\")\n",
    "print(\"have a nice day\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81b9b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Launches Blender from terminal and initiates model download script\n",
    "!.../Blender --python .../Longhand_downloader.py \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

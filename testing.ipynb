{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6cf54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Longhand - M. Cook - 2022\n",
    "##Takes Bag-of-Words and returns multi-user, immersive visualization\n",
    "##https://github.com/Cook4986/Longhand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dcb409",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NER and Parts-of-Speech extraction from HTR bag-of-words\n",
    "#See: https://github.com/Cook4986/SAEF_OCR for more info on HTR pre-processing\n",
    "#Entity types: https://github.com/mchesterkadwell/named-entity-recognition/blob/main/2-named-entity-recognition-of-henslow-data.ipynb\n",
    "import spacy\n",
    "from collections import Counter\n",
    "\n",
    "#declarations\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "BoW = \"/Users/matthewcook/Dropbox/DS/Zaritt/Woman in Chains.txt\"\n",
    "nounOut = open(\"/Users/matthewcook/Dropbox/Viz/Longhand/nouns.txt\", \"w\")\n",
    "    \n",
    "###parse BoW with Spacy\n",
    "with open(BoW, encoding=\"utf-8\") as file:\n",
    "    iliad = file.read()\n",
    "document = nlp(iliad)\n",
    "document.text\n",
    "\n",
    "#collate nouns in BoW input\n",
    "nouns = []\n",
    "for token in document:\n",
    "    if token.pos_ == 'NOUN':\n",
    "        nouns.append(token.text)\n",
    "\n",
    "#Entity Frequency\n",
    "word_freq = Counter(nouns)\n",
    "common_words = word_freq.most_common(100)\n",
    "print(common_words)\n",
    "for noun in common_words:\n",
    "    noun.strip(\"'()[]\")\n",
    "    print(noun)\n",
    "    nounOut.write(str(noun))\n",
    "    nounOut.write(\"\\n\")\n",
    "\n",
    "#close files\n",
    "file.close()\n",
    "nounOut.close()\n",
    "print(\"\\n\")\n",
    "print(\"have a nice day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b1d248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query Sketchfab with nouns and/or named entities and generate list of uids for use in Blender\n",
    "import json\n",
    "import requests\n",
    "from requests.exceptions import RequestException\n",
    "import re\n",
    "import time\n",
    "\n",
    "#declarations\n",
    "SKETCHFAB_API_URL = \"https://api.sketchfab.com/v3/search?type=models\"\n",
    "API_TOKEN = '046f786a59eb4112b9b89ba26a85f85f'\n",
    "common = open(\"/Users/matthewcook/Dropbox/Viz/Longhand/nouns.txt\", \"r\")\n",
    "uid_Out = open(\"/Users/matthewcook/Dropbox/Viz/Longhand/uid.txt\", \"w\")\n",
    "words = []\n",
    "uids = []\n",
    "count = 0\n",
    "start = time.time()\n",
    "\n",
    "#extract noun strings from common words doc\n",
    "for line in common.readlines():\n",
    "    word = line.split()\n",
    "    words.append(word[0]) \n",
    "\n",
    "#Sketchfab API payload function \n",
    "##From https://sketchfab.com/developers/data-api/v3/python#example-python-model\n",
    "def _get_request_payload(*, data=None, files=None, json_payload=False):\n",
    "    \"\"\"Helper method that returns the authentication token and proper content type depending on\n",
    "    whether or not we use JSON payload.\"\"\"\n",
    "    data = data or {}\n",
    "    files = files or {}\n",
    "    headers = {'Authorization': 'Token {}'.format(API_TOKEN)}\n",
    "    if json_payload:\n",
    "        headers.update({'Content-Type': 'application/json'})\n",
    "        data = json.dumps(data)\n",
    "    return {'data': data, 'files': files, 'headers': headers}\n",
    "\n",
    "#query sketchfabs with nouns in BoW and return/write list of uids\n",
    "for word in words:\n",
    "    word = word.strip(\"(),'\")\n",
    "    print(\"Searching: \" + str(word))\n",
    "    print(\"\\n\")\n",
    "    query = (\"&q=\"+(str(word))+\"&downloadable=true\")\n",
    "    search_endpoint = f'{SKETCHFAB_API_URL + query}'\n",
    "    payload = _get_request_payload() \n",
    "    response = requests.get(search_endpoint, **payload)\n",
    "    data = response.json()\n",
    "    for item in range(len(data['results'])):\n",
    "        uid=(data['results'][item]['uid'])\n",
    "        name = (str((data['results'][item]['name'])))\n",
    "        print(\"the following model been located: \")\n",
    "        print(str((data['results'][item]['name']))+(\" \\nuid: \")+(data['results'][item]['uid']))\n",
    "        print(\"\\n\")\n",
    "        uids.append(name +\", \"+ uid)\n",
    "for uid in uids:\n",
    "    uid_Out.write(uid + \"\\n\")\n",
    "    \n",
    "#close program\n",
    "common.close()\n",
    "uid_Out.close()\n",
    "end = time.time()\n",
    "print(str(end - start) + \" seconds elapsed\" )\n",
    "print(\"\\n\")\n",
    "print(\"have a nice day\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81b9b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Launches Blender from terminal and initiates python script, above\n",
    "!/Applications/Blender.app/Contents/MacOS/Blender --python /Users/matthewcook/Longhand/operator_file_import.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef183be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TO DO:\n",
    "#initiate Sketchfab queries in Blender using Blender Python API\n",
    "#place search results in the scene, without overlap, using frequencies\n",
    "#export scene (gltf) for use in hubs\n",
    "#automate scene change function in Hubs, based on newly created gltfs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

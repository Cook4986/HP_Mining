{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Pre-processing for OCR\n",
    "#Portions from Gabe Pizzorno 'Workflow-clean' script\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import re\n",
    "\n",
    "#declarations\n",
    "path='xxx' #target image directory\n",
    "out='xxx' #transcription output path\n",
    "listFiles=os.listdir(path)\n",
    "imgNo = 0\n",
    "\n",
    "#file/os operations\n",
    "for file in sorted(listFiles):\n",
    "    if not file.startswith('.'):\n",
    "        image = cv2.imread(path+'/'+file)\n",
    "        fileName=file.split('.')[0]\n",
    "        img_gs = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        img_bw = cv2.adaptiveThreshold(img_gs, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 91, 5)\n",
    "        img_inv = cv2.bitwise_not(img_bw)\n",
    "        cv2.imshow(fileName, img_inv)\n",
    "        cv2.imwrite(out+\"/\"+fileName+\".jpg\", img_inv) \n",
    "        print(fileName + \" pre-processed and ready for OCR\")\n",
    "        cv2.waitKey(10)\n",
    "        imgNo = int(imgNo) + 1\n",
    "    cv2.destroyAllWindows()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Handprint from local directory\n",
    "!handprint --service microsoft,google,amazon-textract --debug - \"xxx\" --no-grid --extended --output \"xxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run Handprint using URLs from local .txt file\n",
    "!handprint --service microsoft,google,amazon-textract --from-file \"xxx\" --no-grid --extended --output \"xxx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Bag-of-Words txt output and string search from HandPrint transcriptions. MNC - 5/21\n",
    "###Built to work with HandPrint, by Mike Hucka: https://github.com/caltechlibrary/handprint\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "#paths\n",
    "cardPath = 'xxx'#urls or filenames (pre-existing)\n",
    "outPath = 'xxx' #HP output (pre-existing)\n",
    "textOut = 'xxx'#Bag-of-Words output\n",
    "searchOut = 'xxx'#user search output\n",
    "listFiles = os.listdir(outPath)\n",
    "count = 0\n",
    "\n",
    "#declarations\n",
    "headers = [] \n",
    "transcriptions = []\n",
    "BoW = open(textOut, \"a\")\n",
    "\n",
    "#user search\n",
    "search = open(searchOut, \"a\")\n",
    "inputString = input(\"Search document for: \")\n",
    "inputString = str(inputString)\n",
    "\n",
    "#generate header list\n",
    "with open (cardPath, 'rt') as myfile: \n",
    "    for line in myfile:\n",
    "        headers.append(line)\n",
    "\n",
    "#append headers and transcriptions to bag-of-words \n",
    "for file in sorted (listFiles):\n",
    "    if not file.startswith('.') and file.endswith (\".handprint-microsoft.txt\"):\n",
    "        BoW.write(\"\\n\")\n",
    "        BoW.write(headers[count]) #write card location to disk\n",
    "        #print(\"\\n\")\n",
    "        print((headers[count]) + \"added\")\n",
    "        contents = open(outPath + \"/document-\" + str(count + 1) + \".handprint-microsoft.txt\", \"r\") #read card transcription\n",
    "        #contents = open(outPath + \"/\" + file, \"r\") #read card transcription\n",
    "        transcriptions.append(contents.read())\n",
    "        #print(transcriptions[count])\n",
    "        #print(\"\\n\")\n",
    "        BoW.write(transcriptions[count]) #write transcriptions to disk\n",
    "        BoW.write(\"\\n\")\n",
    "        count = count + 1\n",
    "        #print(\"\\n\")    \n",
    "BoW.close()\n",
    "\n",
    "#search\n",
    "BoW = open(textOut, \"r\")\n",
    "count = 0\n",
    "\n",
    "while count < len(headers):\n",
    "    if inputString in transcriptions[count]:\n",
    "        print(headers[count])\n",
    "        print(transcriptions[count])\n",
    "        search.write(\"\\n\")\n",
    "        search.write(headers[count])\n",
    "        search.write(transcriptions[count])\n",
    "        search.write(\"\\n\")\n",
    "        print(\"\\n\")\n",
    "        count = count + 1\n",
    "    elif inputString not in transcriptions[count]:\n",
    "        #print(\"\\n\")\n",
    "        print(\"No such string found in transcription \" + str(count + 1))\n",
    "        #print(\"\\n\")\n",
    "        count = count + 1\n",
    "search.close()\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"have a nice day\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###pdf parser\n",
    "import sys \n",
    "import fitz\n",
    "\n",
    "fname = \"xxx\"  # get document filename\n",
    "doc = fitz.open(fname)  # open document\n",
    "out = open(fname + \".txt\", \"wb\")  # open text output\n",
    "for page in doc:  # iterate the document pages\n",
    "    text = page.get_text().encode(\"utf8\")  # get plain text (is in UTF-8)\n",
    "    out.write(text)  # write text of page\n",
    "    out.write(bytes((12,)))  # write page delimiter (form feed 0x0C)\n",
    "out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "###Natural Language Processing\n",
    "##Modified from \"named-entity-recognition\" repo by Mary Chester-Kadwell\n",
    "##(https://github.com/mchesterkadwell/named-entity-recognition/blob/main/LICENSE)\n",
    "\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "from spacy import displacy\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "#declarations\n",
    "nlp = en_core_web_sm.load()\n",
    "text_file = Path('data', 'xxx.txt')\n",
    "body_parts = open(\"xxx\", \"r\") #cross references, text file\n",
    "\n",
    "# Open the file, read it and store the text with the name `iliad`\n",
    "with open(text_file, encoding=\"utf-8\") as file:\n",
    "    iliad = file.read()\n",
    "\n",
    "#pass text to SpaCy language model()\n",
    "document = nlp(iliad)\n",
    "document.text\n",
    "\n",
    "#generate list of body common parts\n",
    "#Note:\"back\" removed\n",
    "list_of_parts = []\n",
    "for line in body_parts:\n",
    "    stripped_line = line.strip()\n",
    "    #line_list = stripped_line.split()\n",
    "    list_of_parts.append(stripped_line)\n",
    "#print(list_of_parts)\n",
    "\n",
    "#identify nouns in document\n",
    "nouns = []\n",
    "pos_tags = [(token.text, token.pos_, token.tag_) for token in document if token.text.isalpha()]\n",
    "for token in document:\n",
    "    if token.text in list_of_parts:\n",
    "        nouns.append(token.text)\n",
    "#print(nouns)\n",
    "\n",
    "persons = []\n",
    "for entity in document.ents:\n",
    "    if entity.label_ == \"PRODUCT\":\n",
    "        persons.append(entity.text)\n",
    "        #print(f'{entity.text}: {entity.label_}')\n",
    "        \n",
    "#print high-frenquency nouns\n",
    "word_freq = Counter(nouns)\n",
    "common_words = word_freq.most_common(25)\n",
    "print(common_words)\n",
    "\n",
    "# Display the plot inline in the notebook with interactive controls\n",
    "%matplotlib notebook\n",
    "\n",
    "# Get a list of the most common words\n",
    "words = [word for word,_ in common_words]\n",
    "\n",
    "# Get a list of the frequency counts for these words\n",
    "freqs = [count for _,count in common_words]\n",
    "\n",
    "# Set titles, labels, ticks and gridlines\n",
    "plt.title(\"Body part mentions in \"\"Women in Chains\")\n",
    "plt.xlabel(\"Word\")\n",
    "plt.ylabel(\"# of appearances\")\n",
    "plt.xticks(range(len(words)), [str(s) for s in words], rotation=90)\n",
    "plt.grid(b=True, which='major', color='#333333', linestyle='--', alpha=0.5)\n",
    "plt.gcf().subplots_adjust(bottom=0.35)\n",
    "\n",
    "# Plot the frequency counts\n",
    "plt.plot(freqs)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "plt.savefig('xxx.png', bbox_inches=\"tight\")\n",
    "\n",
    "#display named entities\n",
    "displacy.render(document, style=\"ent\")\n",
    "\n",
    "body_parts.close()\n",
    "file.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

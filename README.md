# **Longhand** #
Longhand takes a handwritten text corpus and returns an immersive visualization. 

![throughput diagram](https://images.squarespace-cdn.com/content/v1/532b70b6e4b0dca092974dbe/1627401430752-R7H10DTUUOSB4GKDDKD1/Longhand+Throughput_Cook2021.png?format=2500w)

### Innovations
* Supports “raw” input data, at scale (HTR)
* Leverages large 3D asset collections (Sketchfab)
* Exposes humanities to the benefits of XR 
### Limitations
* Best for nouns (i.e. things) in the corpus
* Proprietary HTR (Amazon, Google, Microsoft)
*Model placement in scene is unsolved 
### Next Steps
* Short term: Hack Hubs, Topic Modeling 
* Long term: Audio, Video, Image support
* Other collections 

## Core Components
 * [OpenCV](https://github.com/opencv/opencv)
 * [HandPrint](https://github.com/caltechlibrary/handprint)
 * [SpaCy](https://github.com/explosion/spaCy)
 * [Hubs](https://github.com/mozilla/hubs)

Matt Cook - 2021
